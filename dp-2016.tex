% -*- TeX-engine: xetex -*-
\documentclass[a4paper]{scrartcl}
% \documentclass[12pt,a4paper]{article}
\pagenumbering{gobble}

% for 0.5cm margins
% \usepackage[left=0.5cm,top=0.5cm,right=0.5cm,bottom=0.5cm,bindingoffset=0cm]{geometry}

\usepackage{libertine}

\usepackage[svgnames,hyperref]{xcolor}
\usepackage{url}
\usepackage{graphicx}

\usepackage{tabulary}
\usepackage{booktabs}

% \usepackage{paralist}
% \usepackage{enumitem}

% monokai code listings

\usepackage[%
backend=biber,
style=numeric-comp,
maxbibnames=10,
sorting=none,
sortcites=true,
url=true,
doi=true
% refsegment=chapter,
% ibidtracker=strict
]{biblatex}

% small references
\renewcommand{\bibfont}{\normalfont\small}

% \AtEveryBibitem{\clearfield{month}}
% \AtEveryCitekey{\clearfield{month}}

% \addbibresource{dp-2016.bib}
\addbibresource{ben-papers.bib}

\usepackage[english=british,threshold=15,thresholdtype=words]{csquotes}
\SetCiteCommand{\parencite}

\usepackage[%
unicode=true,
hyperindex=true,
bookmarks=true,
colorlinks=true, % change to false for final
pdfborder=0,
allcolors=DarkBlue,
% plainpages=false,
pdfpagelabels,
hyperfootnotes=true]{hyperref}

\author{Ben Swift, Henry Gardner, John Grundy, Andrew Sorensen}
\date{\today}
\title{DP '16 Application}

% hyphenation
\hyphenation{ARC}

\begin{document}

\renewcommand{\thesection}{\Alph{section}}

\setcounter{section}{3} % C1.
\subsection{Project Description}
\label{sec:project-description}
% (Please upload a Project Description as detailed in the Instructions
% to Applicants in no more than 10 A4 pages and in the required
% format. Please refer to the Instructions to Applicants for detailed
% instructions on the required content and format of the Project
% Description.)

\subsubsection*{PROJECT TITLE}

A few options:

\begin{enumerate}
\item \textbf{Live <domain-specific> visual programming for complex
    data analytics software}
\item \textbf{Bringing interactivity to high-performance scientific
    computing}
\end{enumerate}

\subsubsection*{AIMS AND BACKGROUND}

\paragraph*{Aims}

The modern world is saturated with computing power, with contemporary
smart phones outperforming the original Cray~1 supercomputer by three
orders of magnitude. Advances in network connectivity and bandwidth
have also made it easier to harness remote computing power---giving
rise to the almost limitless potential of the ``cloud'' for processing
and storing data from anywhere in the world. Accessing
supercomputer-level \textbf{performance} has never been easier and,
when combined with machine learning\cite{Hastie2009} and big
data\cite{Manyika2011}, this performance has the potential to provide
answers to deep questions in science, business and even the
humanities.

Modern computing devices are also spectacularly \textbf{interactive},
enabling users to slide, tap, watch, speak, listen with real-time
feedback. The benefits of interactivity in programming (while long
espoused by lisp programmers) have in more recent times gained more
widespread acceptance, through Agile\parencite{Fowler2001} and
eXtreme\parencite{Beck1999} programming practices, and the emerging
field of live programming\parencite{Swift2013b}.

But is all of this power, interactivity and networked connectivity
working together to tackle cutting-edge computing challenges of the
21st century? Consider the following scenarios:
\begin{enumerate}
\item A computational physicist submits a job to the supercomputer
  which takes 3 weeks to execute. During subsequent data analysis, it
  she discovers that there was an incompatibility in the
  specifications of 2 parameters (out of 200) in the input deck for
  this simulation, which caused the computation to fail to converge.
  The convergence issue is clearly visible in even a text-only dump of
  high-level simulation quantities at each timestep.

% \item a bioinformatics researcher trawls through millions of generated
%   phylogenic candidates in order to match and develop evolutionary
%   trees. A subsequent analysis of the results finds that the stopping
%   criteria were satisfied after only the first hundered such files had
%   been compared.

\item A team of SES personnel are monitoring a real-time satellite
  feed of a bushfire which is hours away from threatening homes and
  lives. A computational simulation of the bushfire is being performed
  to predict the future progress of the firefront, but over time the
  simulation gives unreliable results---the SES experts deduce that
  the model is underestimating the fuel load in the region. The change
  to the model to account for the increased fuel load is not a complex
  one, but the simulation system has not been designed to allow such
  changes while the simulation is running, and restarting the system
  with an updated model takes more time than is anticipated before the
  firefront reaches the housing line.

\item A growing hi-tech manufacturing company has historically relied
  on managing their supply chain by hand. However, as the company
  grows and the number of supplier relationships increases this is no
  longer feasible. A purely automated approach generates suboptimal
  results, because the supply chain involves a complex network of
  human relationships and hand-shake agreements between the suppliers.
  The expert team can see subtle problems with the results (and
  appropriate subtle corrections) as the automated model is running,
  but are prevented by the software from effecting these changes until
  the model has finished running.
\end{enumerate}

These scenarios, and many others, could benefit from a tighter
coupling between the human researchers and their data analytics
software \emph{at run time}. Such enhanced human-in-the-loop (HIL)
workflows are now possible in ways that been hitherto unimaginable.

The aim of this project is to bring human-in-the-loop interactivity to
complex data analysis software workflows, enabling scientists,
programmers and domain experts to take gain new insights into data and
take better advantage of the modern computing and data landscape.

% \begin{itemize}
% \item in a data-centric world, we need lots of big data-oriented
%   software incl data processing and visualisation
% \item current techniques include BI software, data mining/machine
%   learning software, scientific software, social media analysis
%   software \ldots
% \item sorts of things we want to answer include compute behaviours of
%   new materials (science); find important trends (business); learn
%   about phenomenon (social sciences); discover relationships
%   (statistics); \ldots
% \item these not well-addressed by current solutions. We need: more
%   involvement of end users in specifying and realising solutions;
%   better way to model the analysis workflow ; more abstract and visual
%   way to specify and generate complex data analysis algorithms and
%   code ; live update of complex analysis software from visual models ;
%   visualisations of parts and whole large data sets ; live update of
%   visualisations as change visual specifications for interactive
%   feedback to users
% \end{itemize}

\paragraph*{Background}

Due to a combination of technical and social factors, scientific
computing is still often performed in a batch
\emph{compile-run-analyse} style. In 2007, a National Science
Foundation workshop\parencite{Gil2007} outlined several outstanding
challenges in scientific computation and data analysis. These included
data provenance (where data comes from\cite{McPhillips2009}),
reproducibility and shareability of complex data processing software
pipelines, and the need for dynamic interactivity in these workflows.

A key part of the solution to these problems is the development of
Scientific Workflow Management Systems\parencite{Deelman} (SWfMS):
tools for managing the data dependencies, the processing steps and the
computational resources required to perform a complete analysis for a
given problem. Instead of an ad-hoc collection of script files,
compute binaries and inaccessible data stores, a SWfMS allows the
complete set of conditions required to perform the analysis to be
captured in an unambiguous way, allowing the same (or derived)
analyses to be performed by other groups (or the same group at a later
time, or with new data) to allow for better sharing of knowledge and
greater confidence in the results.

In a more recent (2014) review of the field, ``Dynamic steering of HPC
scientific workflows: A survey''\parencite{Mattoso}, Mattoso et~al.
attempt to map out the current SWfMS landscape in regard to dynamic
workflow steering (the ability to view and modify a running
computational process in real time). They identified six key areas of
interaction/steering:
\begin{enumerate}
\item \textbf{monitoring}: the ability to monitor intermediate
  quantities of interest (e.g. total energy)
\item \textbf{analysis}: the ability to perform analysis of simulation
  quantities (e.g. viewing a live histogram of the energy
  distribution)
\item \textbf{adaptation}: the ability to adapt/modify the running
  simulation
\item \textbf{notification}: the ability of the system to alert users of the
  need/opportunity to interfere
\item \textbf{interface for interaction}: the interface (either command-based
  or GUI) presented to the user to monitor and adapt the computation
\item \textbf{computing model}: the ability to tailor the types of interaction
  depending on the compute model in use (e.g. providing full
  monitoring when running locally on a workstation vs only statistical
  sampling when the job is distributed over a cluster)
\end{enumerate}
At the end of their survey, Mattoso et~al. present some open
challenges for dynamic steering in scientific computing workflows.
Specifically, the \emph{analysis} and \emph{adaptation} branches of
their taxonomy are not well addressed by current SWfMS.

In terms of real-time analysis, the open challenges are:
\begin{itemize}
\item \textbf{in-situ analysis}: modern terascale compute
  infrastructure is often IO-bound, and HPC applications must minimize
  inter-node communication to achieve efficient use of the hardware.
  As a result, it is often unfeasible to move the data of interest
  back to a central node for processing and analysis, so any such
  analysis must be performed in-situ\cite{Bennett2012} on the compute
  node itself.
\item \textbf{Decision-support tools}: giving a user the
  \emph{ability} to interfere with a running computational process is
  one thing---knowing \emph{when and how} to interfere is another
  thing altogether. Dynamic SWfMS must provide as useful real-time
  feedback to the user (a domain expert) to assist them in deciding
  when and how to interfere. This problem is an example of a more
  general end-user programming (EUP)\cite{Myers2006} problem---giving
  domain experts the appropriate tools to transfer their domain
  expertise into the computational domain.
\end{itemize}
In the area of adaptation, the open challenges are:
\begin{itemize}
\item \textbf{dynamic workflow engines}: most of the surveyed systems
  allowed the user to adapt the computation at a high level (e.g.
  add/delete subtasks). However, there was much less support for
  modifying the evolution of specific tasks (e.g. swapping out
  low-level algorithms and tight-loops in computation). This level of
  adaptivity would allow for even more steering possibilities, but may
  exacerbate the problem of deciding when/how to interfere (although
  support for rolling back interventions would be helpful here).
\item \textbf{parameter slice exploration}: many scientific problems
  involve searching high-dimensional parameter spaces for optimal
  parameter configurations, and many algorithms exist for this task.
  However, there are some problems (e.g. buisness informatics) where
  cost/loss functions are hard to articulate, and more traditional
  purely numerical optimization approaches tend to overfit or get
  stuck in local maxima. In these situations an expert domain user, if
  presented with appropriate feedback in real-time, may be able to
  recognise these type of convergence problems early on, and perform
  appropriate algorithmic and parameter adaptations to avoid the
  problem.
\end{itemize}

\textbf{Note to readers:} there is lots of related work which has not
been covered, e.g. the benefits of interactive (or live) programming
more generally, plus the literature on computational steering, and the
EUP/VL literature. Will put that stuff in as the document develops.

% BACKGROUND

% - live programming
% - live programming applications to date
% - HPC software
% - Data mining \& Machine learning software
% - BI software
% - DSLs, DSVLs ; applied to above
% - information visualisation
% - live infoVis


\subsubsection*{RESEARCH PROJECT}

This project will unlock new ways to perform complex computation
analyses through three steps:

\begin{enumerate}
\item \textbf{explore}: first, by exploring the problem domain (and
  existing tools) of interest in conjunction with domain experts, do
  determine the dimensions of the domain which could most benefit from
  interactive, human-in-the-loop analysis
\item \textbf{enliven}: using tools and techniques from live
  programming, provide components (which fit into existing SWfMS)
  which are amenable to live modification
\item \textbf{empower}: creating appropriate interfaces (e.g.
  domain-specific visual languages) to empower domain experts to
  unlock their expertise in interactive computational simulation
\end{enumerate}

\textbf{Note to Henry:} here's where I'm up to. The stuff from here on
in is just notes, mostly taken from John's initial email.

% explore $\rightarrow$ enliven $\rightarrow$ empower

% Want to bring the idea of "liveness" to HPC/big data software â€“ allow
% developers to get rapid, incremental update of target data process
% algs ; allow developers to get near-instantaneous feedback on input of
% changes to outputs data via rich visualisations

% Want to leverage domain-specific visual languages to specify these big
% data analysis problems to enable end users a high-level, controlled
% environment c.f. R-type scripting, code, BI configs etc

% Want to leverage rich information visualisations to provide small
% snapshot and overall output understanding by end users

% << Worth a big picture "concept diagram" here >>

% The aim of this project is thus to invent a new approach to specifying
% and realizing data-centric software systems using live visual
% programming and data visualisation we break into specific aims:

% - SDL++ for data analytics
% - Live visual programming of data analytics - DSVLs
% - extempore -> live update of GPU/HPC/IR/ML algs etc
% - live visualisations of complex data analytics alg data for feedback,
%   output
% - evaluate effectiveness by apply to several exemplars e.g. particles,
%   big data analysis, infoVis...

\paragraph*{Research significance}

Big data software, HPC software becoming massively important
Development of both still rudimentary, limited use of "liveness"
concept in HPC/DSVLs to date (some in InfoVis). Many applications of
our approach; a very enabling technology. Examples might include\ldots

\paragraph*{Advancing the knowledge base with innovation}

\begin{itemize}
\item very limited use of "liveness" concept to date in BI, HPC, etc ;
  adding into these very novel
\item limited DSVLs leveraged to date in these domains ; enables end
  users
\item InfoVis well studied but specification low-level, limited ;
  enables greater generality
\item running the concept of "liveness" through these: DSVLs <->
  HPC/Big Data code <-> InfoVis
\end{itemize}

\paragraph*{Conceptual}

Series of research problems to be solved:

\begin{enumerate}
\item Add ability to modify HPC/Big Data code while
  running---"liveness"
\item Invent set of DSVLs for specifying such applications
\item Use DSVLs to generate code / modify code (via 2, 1 above)
\item Specifying rich, live InfoVis solution for data processed (by 1
  above)
\item Evaluate effectivess on set of exemplars
\end{enumerate}

\paragraph*{Feasibility, methodology and timeline}

% -set of steps
% -set of prototype interations

% Work per quarter

\paragraph*{Outcomes and impact}



\paragraph*{National benefit and strategic research priorities}



\subsubsection*{ROLE OF PERSONNEL}



\subsubsection*{RESEARCH ENVIRONMENT}

\paragraph*{Existing research environment}



\paragraph*{Developing research environment}



\paragraph*{Collaboration, communication and commercialization}



\subsubsection*{COMMUNICATION OF RESULTS}

reproducable code/software artefacts

\subsubsection*{MANAGEMENT OF DATA}

Data provenance, reproducibility

\subsubsection*{REFERENCES}

\vskip -2em % filthy hack to get the spacing right

\printbibliography[title=\ ]

\newpage
\setcounter{section}{5} % E1.
\setcounter{subsection}{0}
\subsection{Justification of funding requested from the ARC for the
  duration of the Project}
\label{sec:funding-justification}
% (In no more than 5 A4 pages and within the required format fully
% justify, in terms of need and cost, each budget item requested from
% the ARC. Use the same headings as in the Description column in the
% budget at Part D of this Proposal. )



\newpage
% E2.
\subsection{Details of non-ARC contributions}
\label{sec:non-arc-contributions}
% (In no more than 2 A4 pages and within the required format, provide
% an explanation of how non-ARC contributions will support the
% proposed Project. Use the same headings as in the Description column
% in the budget at Part D of this Proposal. )


\newpage
\setcounter{section}{6}
\setcounter{subsection}{11} % F12. 
\subsection{Research Opportunity and Performance Evidence (ROPE)\\
  Recent significant research outputs and ARC grants (since 2005)}
\label{sec:recent-significant-outputs}
% (Please attach a PDF with a list of your recent significant research
% outputs and ARC grants most relevant to this Proposal (20 pages
% maximum). Please refer to the Instructions to Applicants for the
% required content and formatting.)



\newpage
% F13. 
\subsection{Research Opportunity and Performance Evidence (ROPE)\\
  Ten career-best research outputs}
\label{sec:ten-best-outputs}
% (Please attach a PDF with a list of your 10 career-best research
% outputs, with a brief paragraph for each output explaining its
% significance (5 pages maximum). Please refer to the Instructions to
% Applicants for the required content and formatting.)



\newpage
\setcounter{section}{7} % G1. 
\setcounter{subsection}{0}
\subsection{Research support from sources other than the ARC}
\label{sec:other-research-support}
% (For all participants on this Proposal, please provide details of
% research funding from sources other than the ARC (in Australia and
% overseas) for the years 2014 to 2018 inclusive. That is, list all
% Projects/Proposals/Fellowships awarded or requests submitted for
% funding involving the Proposal participants. Please refer to the
% Instructions to Applicants for submission requirements.)

\end{document}
